{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Task 3 – Exploratory Analysis (Python)\n",
            "\n",
            "## 1. Data Understanding & Cleaning\n",
            "- Load the datasets\n",
            "- Handle missing values or outliers if necessary"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "#301360037\n",
            "#maaz bobat\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "import json\n",
            "# load the data into a pandas dataframe\n",
            "df_events = pd.read_csv(\"../data/events.csv\")\n",
            "df_devices = pd.read_csv(\"../data/devices.csv\")\n",
            "df_users = pd.read_csv(\"../data/users.csv\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "(121, 4)\n",
                  "    user_id signup_date         region  platform\n",
                  "0  739b720a  2023-04-21  United States       iOS\n",
                  "1  0aa3325c  2023-06-12             US       iOS\n",
                  "2  b5a2048e  2023-08-20             KR       Web\n",
                  "3  a4a70166  2023-05-26            can  3rdParty\n",
                  "4  2386e2a0  2023-01-18            USA   Android \n",
                  "\n",
                  "         user_id signup_date         region platform\n",
                  "count        121         121            121      121\n",
                  "unique       120         103              8        4\n",
                  "top     739b720a  2023-04-21  United States      iOS\n",
                  "freq           2           2             18       32 \n",
                  "\n",
                  "Missing values (Users):\n",
                  "user_id        0\n",
                  "signup_date    0\n",
                  "region         0\n",
                  "platform       0\n",
                  "dtype: int64\n",
                  "Unique Regions:   ['United States' 'US' 'KR' 'can' 'USA' 'CA' 'JP' 'Canada']\n",
                  "Unique Platforms: ['iOS' 'Web' '3rdParty' 'Android']\n"
               ]
            }
         ],
         "source": [
            "# ---- Explore Users -----\n",
            "# number of rows and columns.\n",
            "print(df_users.shape)\n",
            "# Print first 5 rows to understand the data structure\n",
            "print(df_users.head(), \"\\n\")\n",
            "# statistical summary of the dataset\n",
            "print(df_users.describe(), \"\\n\")\n",
            "print(\"Missing values (Users):\")\n",
            "print(df_users.isnull().sum())\n",
            "# Unique values for categorical columns\n",
            "print(\"Unique Regions:  \", df_users[\"region\"].unique())\n",
            "print(\"Unique Platforms:\", df_users[\"platform\"].unique())\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "devices shape: (450, 6)\n",
                  "    device_id   user_id network device_type firmware_version location\n",
                  "0  d_f4abcb9e  89a25ef6    tuya         fan            1.0.3   Office\n",
                  "1  d_212b804b  2f555493    tuya  smart_plug            1.0.0      NaN\n",
                  "2  d_32b272b3  f41317b2    tuya      heater         3.5.beta      NaN\n",
                  "3  d_f6fe781d  ee413bc3    tuya         fan         3.5.beta      NaN\n",
                  "4  d_8555efd8  cd6e76a2    tuya  smart_bulb         3.5.beta     Home \n",
                  "\n",
                  "         device_id   user_id network device_type firmware_version location\n",
                  "count          450       425     450         450              450      342\n",
                  "unique         450       119       2           8                4        3\n",
                  "top     d_9f01e3d6  739b720a    tuya  thermostat            2.1.0     Home\n",
                  "freq             1        10     228          70              115      136 \n",
                  "\n",
                  "Missing values (Devices):\n",
                  "device_id             0\n",
                  "user_id              25\n",
                  "network               0\n",
                  "device_type           0\n",
                  "firmware_version      0\n",
                  "location            108\n",
                  "dtype: int64\n",
                  "Unique Networks:          ['tuya' 'ayla']\n",
                  "Unique Device Types:      ['fan' 'smart_plug' 'heater' 'smart_bulb' 'door_sensor' 'legrand_switch'\n",
                  " 'thermostat' 'window_sensor']\n",
                  "Unique Firmware Versions: ['1.0.3' '1.0.0' '3.5.beta' '2.1.0']\n",
                  "Unique Locations:         ['Office' nan 'Home' 'Cottage']\n",
                  "\n",
                  "Duplicate device_ids: 0\n"
               ]
            }
         ],
         "source": [
            "# ----Explore Devices----\n",
            "# number of rows and columns.\n",
            "print(\"devices shape:\", df_devices.shape)\n",
            "# Print first 5 rows to understand the data structure\n",
            "print(df_devices.head(), \"\\n\")\n",
            "# statistical summary of the dataset\n",
            "print(df_devices.describe(), \"\\n\")\n",
            "print(\"Missing values (Devices):\")\n",
            "print(df_devices.isnull().sum())\n",
            "# Unique values for categorical columns\n",
            "print(\"Unique Networks:         \", df_devices[\"network\"].unique())\n",
            "print(\"Unique Device Types:     \", df_devices[\"device_type\"].unique())\n",
            "print(\"Unique Firmware Versions:\", df_devices[\"firmware_version\"].unique())\n",
            "print(\"Unique Locations:        \", df_devices[\"location\"].unique())\n",
            "print(f\"\\nDuplicate device_ids: {df_devices.duplicated(subset='device_id').sum()}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "(15000, 6)\n",
                  "  event_id   device_id event_type  event_value                  event_ts  \\\n",
                  "0      e_0  d_87cfe321  telemetry  see_payload  2024-01-18T17:45:43.000Z   \n",
                  "1      e_1  d_fddd9d33  telemetry  see_payload  2024-02-04T16:18:19.000Z   \n",
                  "2      e_2  d_c5859fb6  telemetry  see_payload  2024-01-12T10:57:04.000Z   \n",
                  "3      e_3  d_de3f2763  telemetry  see_payload  2024-01-02T08:09:18.000Z   \n",
                  "4      e_4  d_8406c179  telemetry  see_payload  2024-01-23T01:15:16.000Z   \n",
                  "\n",
                  "                                             payload  \n",
                  "0  {\"metadata\": {\"oem_model\": \"door_sensor\", \"dsn...  \n",
                  "1  {\"metadata\": {\"oem_model\": \"window_sensor\", \"d...  \n",
                  "2  {\"status\": [{\"code\": \"generic_state\", \"value\":...  \n",
                  "3  {\"status\": [{\"code\": \"switch_led\", \"value\": fa...  \n",
                  "4  {\"status\": [{\"code\": \"generic_state\", \"value\":...   \n",
                  "\n",
                  "       event_id   device_id event_type  event_value                  event_ts  \\\n",
                  "count     15000       15000      15000        15000                     15000   \n",
                  "unique    15000         450          1            1                     14976   \n",
                  "top     e_14999  d_f4abcb9e  telemetry  see_payload  2024-01-12T15:49:47.000Z   \n",
                  "freq          1        1517      15000        15000                         2   \n",
                  "\n",
                  "                                                  payload  \n",
                  "count                                               15000  \n",
                  "unique                                              10002  \n",
                  "top     {\"status\": [{\"code\": \"generic_state\", \"value\":...  \n",
                  "freq                                                 4999   \n",
                  "\n",
                  "event_id       0\n",
                  "device_id      0\n",
                  "event_type     0\n",
                  "event_value    0\n",
                  "event_ts       0\n",
                  "payload        0\n",
                  "dtype: int64\n",
                  "Unique event_types: ['telemetry']\n",
                  "Unique event_values: ['see_payload']\n",
                  "\n",
                  "── Payload A ──\n",
                  "{\n",
                  "  \"metadata\": {\n",
                  "    \"oem_model\": \"door_sensor\",\n",
                  "    \"dsn\": \"ACD6F3E680-6\"\n",
                  "  },\n",
                  "  \"datapoint\": {\n",
                  "    \"property\": \"contact_state\",\n",
                  "    \"value\": 1,\n",
                  "    \"echo\": false\n",
                  "  }\n",
                  "}\n",
                  "\n",
                  "── Payload B ──\n",
                  "{\n",
                  "  \"status\": [\n",
                  "    {\n",
                  "      \"code\": \"generic_state\",\n",
                  "      \"value\": \"online\"\n",
                  "    }\n",
                  "  ]\n",
                  "}\n",
                  "\n",
                  "Payload A → network: ayla\n",
                  "Payload B → network: tuya\n",
                  "\n",
                  "Duplicate event_ids:      0\n",
                  "Duplicate timestamps:     24 — may indicate batch reporting or duplicate submissions\n",
                  "\n",
                  "NOTE: 'event_value' column contains only 'see_payload' for all rows.\n",
                  "All meaningful values are embedded in the 'payload' JSON column.\n",
                  "Parse errors: 0\n",
                  "\n",
                  "── Ayla Payload Keys (datapoint.property) ──\n",
                  "  contact_state                  3228 occurrences\n",
                  "  local_temperature              2092 occurrences\n",
                  "  connectivity                   1361 occurrences\n",
                  "\n",
                  "── Tuya Payload Keys (status[].code) ──\n",
                  "  generic_state                  4999 occurrences\n",
                  "  switch_led                     1890 occurrences\n",
                  "  bright_value                   1890 occurrences\n",
                  "  temp_value                     1890 occurrences\n",
                  "  switch_1                       1430 occurrences\n",
                  "  countdown_1                    1430 occurrences\n",
                  "  cur_current                    1430 occurrences\n",
                  "  cur_power                      1430 occurrences\n",
                  "  cur_voltage                    1430 occurrences\n"
               ]
            }
         ],
         "source": [
            "# ----- Explore Events -----\n",
            "print(df_events.shape)\n",
            "print(df_events.head(), \"\\n\")\n",
            "print(df_events.describe(), \"\\n\")\n",
            "print(df_events.isnull().sum())\n",
            "\n",
            "# Sample one payload per structure to understand what we're working with\n",
            "print(\"Unique event_types:\", df_events[\"event_type\"].unique())\n",
            "print(\"Unique event_values:\", df_events[\"event_value\"].unique())\n",
            "\n",
            "# Inspect two raw payloads to identify the two structures\n",
            "sample_metadata = df_events[df_events[\"payload\"].str.contains('\"metadata\"')].iloc[0]\n",
            "sample_status = df_events[df_events[\"payload\"].str.contains('\"status\"')].iloc[0]\n",
            "\n",
            "print(\"\\n── Payload A ──\")\n",
            "print(json.dumps(json.loads(sample_metadata[\"payload\"]), indent=2))\n",
            "print(\"\\n── Payload B ──\")\n",
            "print(json.dumps(json.loads(sample_status[\"payload\"]), indent=2))\n",
            "\n",
            "# Cross reference to confirm which structure belongs to which network\n",
            "device_a = df_devices[df_devices[\"device_id\"] == sample_metadata[\"device_id\"]][\n",
            "    [\"device_id\", \"network\"]\n",
            "]\n",
            "device_b = df_devices[df_devices[\"device_id\"] == sample_status[\"device_id\"]][\n",
            "    [\"device_id\", \"network\"]\n",
            "]\n",
            "print(\"\\nPayload A → network:\", device_a[\"network\"].values[0])\n",
            "print(\"Payload B → network:\", device_b[\"network\"].values[0])\n",
            "\n",
            "print(f\"\\nDuplicate event_ids:      {df_events.duplicated(subset='event_id').sum()}\")\n",
            "print(\n",
            "    f\"Duplicate timestamps:     {df_events.duplicated(subset='event_ts').sum()} — may indicate batch reporting or duplicate submissions\"\n",
            ")\n",
            "print(\"\\nNOTE: 'event_value' column contains only 'see_payload' for all rows.\")\n",
            "print(\"All meaningful values are embedded in the 'payload' JSON column.\")\n",
            "ayla_codes = {}\n",
            "tuya_codes = {}\n",
            "parse_errors = 0\n",
            "\n",
            "for raw in df_events[\"payload\"]:\n",
            "    try:\n",
            "        data = json.loads(raw)\n",
            "    except (json.JSONDecodeError, TypeError):\n",
            "        parse_errors += 1\n",
            "        continue\n",
            "\n",
            "    # Ayla structure — collect datapoint property names\n",
            "    if \"metadata\" in data and \"datapoint\" in data:\n",
            "        prop = data[\"datapoint\"].get(\"property\")\n",
            "        if prop:\n",
            "            ayla_codes[prop] = ayla_codes.get(prop, 0) + 1\n",
            "\n",
            "    # Tuya structure — collect all status codes\n",
            "    elif \"status\" in data and isinstance(data[\"status\"], list):\n",
            "        for item in data[\"status\"]:\n",
            "            code = item.get(\"code\")\n",
            "            if code:\n",
            "                tuya_codes[code] = tuya_codes.get(code, 0) + 1\n",
            "\n",
            "print(f\"Parse errors: {parse_errors}\")\n",
            "\n",
            "print(\"\\n── Ayla Payload Keys (datapoint.property) ──\")\n",
            "for k, v in sorted(ayla_codes.items(), key=lambda x: -x[1]):\n",
            "    print(f\"  {k:<30} {v} occurrences\")\n",
            "\n",
            "print(\"\\n── Tuya Payload Keys (status[].code) ──\")\n",
            "for k, v in sorted(tuya_codes.items(), key=lambda x: -x[1]):\n",
            "    print(f\"  {k:<30} {v} occurrences\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Duplicate user_ids dropped: 1\n",
                  "Shape: (120, 4)\n",
                  "region\n",
                  "US    47\n",
                  "CA    45\n",
                  "KR    17\n",
                  "JP    11\n"
               ]
            }
         ],
         "source": [
            "# ---- Clean Users ----\n",
            "# only US and Canada have the messy variants. Any region not in region_map will be set to Other\n",
            "region_map = {\n",
            "    \"United States\": \"US\",\n",
            "    \"USA\": \"US\",\n",
            "    \"US\": \"US\",\n",
            "    \"Canada\": \"CA\",\n",
            "    \"can\": \"CA\",\n",
            "    \"CA\": \"CA\",\n",
            "    \"KR\": \"KR\",\n",
            "    \"JP\": \"JP\",\n",
            "}\n",
            "df_users[\"region\"] = df_users[\"region\"].map(region_map).fillna(\"Other\")\n",
            "# Parse signup_date to datetime\n",
            "df_users[\"signup_date\"] = pd.to_datetime(df_users[\"signup_date\"])\n",
            "#count duplicate\n",
            "dupe_count = df_users.duplicated(subset=\"user_id\", keep=\"first\").sum()\n",
            "# Drop duplicate user_id\n",
            "df_users = df_users.drop_duplicates(subset=\"user_id\", keep=\"first\")\n",
            "print(f\"Duplicate user_ids dropped: {dupe_count}\")\n",
            "print(f\"Shape: {df_users.shape}\")\n",
            "print(df_users[\"region\"].value_counts().to_string())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Location nulls filled:       108\n",
                  "Orphan devices (no user_id): 25\n",
                  "Events from orphan devices:  749\n",
                  "Devices on beta firmware:    115\n",
                  "Beta firmware + no user_id:  4 — highest data quality risk devices\n",
                  "Beta firmware (3.5.beta) may produce unreliable telemetry.\n"
               ]
            }
         ],
         "source": [
            "# ---Clean Devices ---\n",
            "df_devices[\"location\"] = df_devices[\"location\"].fillna(\"Unknown\")\n",
            "df_devices[\"user_id_missing\"] = df_devices[\"user_id\"].isnull()\n",
            "\n",
            "orphan_events = df_events.merge(\n",
            "    df_devices[[\"device_id\", \"user_id_missing\"]], on=\"device_id\", how=\"left\"\n",
            ")\n",
            "\n",
            "print(f\"Location nulls filled:       {(df_devices['location'] == 'Unknown').sum()}\")\n",
            "print(f\"Orphan devices (no user_id): {df_devices['user_id_missing'].sum()}\")\n",
            "print(f\"Events from orphan devices:  {orphan_events['user_id_missing'].sum()}\")\n",
            "print(\n",
            "    f\"Devices on beta firmware:    {(df_devices['firmware_version'] == '3.5.beta').sum()}\"\n",
            ")\n",
            "beta_orphan_overlap = df_devices[\n",
            "    (df_devices[\"firmware_version\"] == \"3.5.beta\") & (df_devices[\"user_id_missing\"])\n",
            "].shape[0]\n",
            "print(f\"Beta firmware + no user_id:  {beta_orphan_overlap} — highest data quality risk devices\")\n",
            "print(\"Beta firmware (3.5.beta) may produce unreliable telemetry.\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Parsing payload column (15,000 rows)...\n",
                  "── Events Cleaned ──\n",
                  "Shape: (15000, 18)\n",
                  "\n",
                  "Payload source breakdown:\n",
                  "source\n",
                  "tuya    8319\n",
                  "ayla    6681\n",
                  "\n",
                  "All unique extracted codes:\n",
                  "extracted_code\n",
                  "generic_state        4999\n",
                  "contact_state        3228\n",
                  "local_temperature    2092\n",
                  "switch_led           1890\n",
                  "switch_1             1430\n",
                  "connectivity         1361\n",
                  "\n",
                  "Dedicated measurement columns:\n",
                  "  temperature_c: 2092 readings\n",
                  "  voltage_v:     1430 readings\n",
                  "  current_a:     1430 readings\n",
                  "  power_w:       1430 readings\n",
                  "\n",
                  "extracted_value_numeric non-null: 8640 / 15000\n",
                  "Note: String values like 'online', 'open', 'closed' are intentionally NaN — use extracted_value for categorical analysis.\n",
                  "Duplicate timestamps in events: 24 — kept all rows, could be batch reporting from same device tick\n"
               ]
            }
         ],
         "source": [
            "# Clean Events (Handle Payload)\n",
            "def parse_payload(raw):\n",
            "    try:\n",
            "        data = json.loads(raw)\n",
            "    except (json.JSONDecodeError, TypeError):\n",
            "        return pd.Series(\n",
            "            {\n",
            "                \"source\": \"parse_error\",\n",
            "                \"extracted_code\": None,\n",
            "                \"extracted_value\": None,\n",
            "                \"voltage\": None,\n",
            "                \"current\": None,\n",
            "                \"power\": None,\n",
            "                \"temperature_c\": None,\n",
            "            }\n",
            "        )\n",
            "\n",
            "    # Ayla structure\n",
            "    if \"metadata\" in data and \"datapoint\" in data:\n",
            "        prop = data[\"datapoint\"].get(\"property\")\n",
            "        value = data[\"datapoint\"].get(\"value\")\n",
            "        return pd.Series(\n",
            "            {\n",
            "                \"source\": \"ayla\",\n",
            "                \"extracted_code\": prop,\n",
            "                \"extracted_value\": value,\n",
            "                \"voltage\": None,\n",
            "                \"current\": None,\n",
            "                \"power\": None,\n",
            "                \"temperature_c\": value if prop == \"local_temperature\" else None,\n",
            "            }\n",
            "        )\n",
            "\n",
            "    # Tuya structure — loop all status items to capture multi-value events\n",
            "    if \"status\" in data and isinstance(data[\"status\"], list) and data[\"status\"]:\n",
            "        status_map = {\n",
            "            item.get(\"code\"): item.get(\"value\")\n",
            "            for item in data[\"status\"]\n",
            "            if item.get(\"code\")\n",
            "        }\n",
            "        first = data[\"status\"][0]\n",
            "        return pd.Series(\n",
            "            {\n",
            "                \"source\": \"tuya\",\n",
            "                \"extracted_code\": first.get(\"code\"),\n",
            "                \"extracted_value\": first.get(\"value\"),\n",
            "                \"voltage\": status_map.get(\"cur_voltage\"),  # raw ÷ 10 = volts\n",
            "                \"current\": status_map.get(\"cur_current\"),  # raw ÷ 1000 = amps\n",
            "                \"power\": status_map.get(\"cur_power\"),  # raw ÷ 10 = watts\n",
            "                \"temperature_c\": status_map.get(\"local_temperature\"),\n",
            "            }\n",
            "        )\n",
            "\n",
            "    return pd.Series(\n",
            "        {\n",
            "            \"source\": \"unknown\",\n",
            "            \"extracted_code\": None,\n",
            "            \"extracted_value\": None,\n",
            "            \"voltage\": None,\n",
            "            \"current\": None,\n",
            "            \"power\": None,\n",
            "            \"temperature_c\": None,\n",
            "        }\n",
            "    )\n",
            "\n",
            "\n",
            "print(\"Parsing payload column (15,000 rows)...\")\n",
            "parsed = df_events[\"payload\"].apply(parse_payload)\n",
            "df_events = pd.concat([df_events, parsed], axis=1)\n",
            "\n",
            "# Parse timestamp and extract date for daily aggregations\n",
            "df_events[\"event_ts\"] = pd.to_datetime(df_events[\"event_ts\"], utc=True)\n",
            "df_events[\"date\"] = df_events[\"event_ts\"].dt.date\n",
            "\n",
            "# Convert extracted_value to numeric — booleans (True/False) become 1/0\n",
            "df_events[\"extracted_value_numeric\"] = pd.to_numeric(\n",
            "    df_events[\"extracted_value\"].apply(lambda x: int(x) if isinstance(x, bool) else x),\n",
            "    errors=\"coerce\",\n",
            ")\n",
            "\n",
            "# Scale raw Tuya electrical values to proper units\n",
            "df_events[\"voltage_v\"] = df_events[\"voltage\"] / 10\n",
            "df_events[\"current_a\"] = df_events[\"current\"] / 1000\n",
            "df_events[\"power_w\"] = df_events[\"power\"] / 10\n",
            "\n",
            "print(\"── Events Cleaned ──\")\n",
            "print(f\"Shape: {df_events.shape}\")\n",
            "print(f\"\\nPayload source breakdown:\")\n",
            "print(df_events[\"source\"].value_counts().to_string())\n",
            "print(f\"\\nAll unique extracted codes:\")\n",
            "print(df_events[\"extracted_code\"].value_counts().to_string())\n",
            "print(f\"\\nDedicated measurement columns:\")\n",
            "print(f\"  temperature_c: {df_events['temperature_c'].notna().sum()} readings\")\n",
            "print(f\"  voltage_v:     {df_events['voltage_v'].notna().sum()} readings\")\n",
            "print(f\"  current_a:     {df_events['current_a'].notna().sum()} readings\")\n",
            "print(f\"  power_w:       {df_events['power_w'].notna().sum()} readings\")\n",
            "\n",
            "print(f\"\\nextracted_value_numeric non-null: {df_events['extracted_value_numeric'].notna().sum()} / {len(df_events)}\")\n",
            "print(\"Note: String values like 'online', 'open', 'closed' are intentionally NaN — use extracted_value for categorical analysis.\")\n",
            "\n",
            "dup_ts = df_events.duplicated(subset=\"event_ts\").sum()\n",
            "print(f\"Duplicate timestamps in events: {dup_ts} — kept all rows, could be batch reporting from same device tick\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "network  source\n",
                  "ayla     ayla      6681\n",
                  "tuya     tuya      8319\n",
                  "dtype: int64\n",
                  "Events with unknown device_id: 0\n",
                  "\n",
                  "---- Final Dataset Summary ----\n",
                  "Users:   120 rows | Regions: ['CA', 'JP', 'KR', 'US']\n",
                  "Devices: 450 rows | Networks: ['tuya', 'ayla']\n",
                  "Events:  15000 rows | Date range: 2024-01-01 → 2024-02-07\n",
                  "\n",
                  "---- Data Quality Summary ----\n",
                  "  Duplicate user_ids dropped:          1\n",
                  "  Region variants normalized:          United States/USA → US, Canada/can → CA\n",
                  "  Orphan devices (no user_id):         25\n",
                  "  Events from orphan devices:          749\n",
                  "  Devices on beta firmware (3.5.beta): 115 — telemetry reliability risk\n",
                  "  Beta firmware + no user_id:          4 — highest risk\n",
                  "  Location nulls filled as 'Unknown':  108\n",
                  "  Duplicate event timestamps:          24 — kept, likely batch reporting\n",
                  "  event_value column:                  placeholder only ('see_payload') — real values in parsed payload columns\n",
                  "  extracted_value_numeric non-null:    8640 / 15000 rows\n"
               ]
            }
         ],
         "source": [
            "# ---Verify + Final Summary--\n",
            "df_check = df_events.merge(\n",
            "    df_devices[[\"device_id\", \"network\"]], on=\"device_id\", how=\"left\"\n",
            ")\n",
            "print(df_check.groupby([\"network\", \"source\"]).size())\n",
            "print(f\"Events with unknown device_id: {df_check['network'].isna().sum()}\")\n",
            "\n",
            "print(\"\\n---- Final Dataset Summary ----\")\n",
            "print(f\"Users:   {df_users.shape[0]} rows | Regions: {sorted(df_users['region'].unique())}\")\n",
            "print(f\"Devices: {df_devices.shape[0]} rows | Networks: {df_devices['network'].unique().tolist()}\")\n",
            "print(f\"Events:  {df_events.shape[0]} rows | Date range: {df_events['date'].min()} → {df_events['date'].max()}\")\n",
            "print(\"\\n---- Data Quality Summary ----\")\n",
            "print(f\"  Duplicate user_ids dropped:          1\")\n",
            "print(f\"  Region variants normalized:          United States/USA → US, Canada/can → CA\")\n",
            "print(f\"  Orphan devices (no user_id):         {df_devices['user_id_missing'].sum()}\")\n",
            "print(f\"  Events from orphan devices:          {orphan_events['user_id_missing'].sum()}\")\n",
            "print(f\"  Devices on beta firmware (3.5.beta): {(df_devices['firmware_version'] == '3.5.beta').sum()} — telemetry reliability risk\")\n",
            "print(f\"  Beta firmware + no user_id:          {beta_orphan_overlap} — highest risk\")\n",
            "print(f\"  Location nulls filled as 'Unknown':  {(df_devices['location'] == 'Unknown').sum()}\")\n",
            "print(f\"  Duplicate event timestamps:          {df_events.duplicated(subset='event_ts').sum()} — kept, likely batch reporting\")\n",
            "print(f\"  event_value column:                  placeholder only ('see_payload') — real values in parsed payload columns\")\n",
            "print(f\"  extracted_value_numeric non-null:    {df_events['extracted_value_numeric'].notna().sum()} / {len(df_events)} rows\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2. Visualizations\n",
            "Produce at least 3 meaningful charts, such as:\n",
            "- Event volume over time\n",
            "- Events per device or per user\n",
            "- Comparison between Ayla vs Tuya devices\n",
            "- Highlight any anomalies or interesting patterns"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Your code here"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Task 4 – Hypotheses & Questions\n",
            "\n",
            "1. Propose 2–3 hypotheses about user or device behavior.\n",
            "2. Show how you would test each hypothesis with the available data.\n",
            "3. Clearly state whether the data supports, partially supports, or does not support the hypothesis."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Your code for hypothesis testing here"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Task 5 – Reflection\n",
            "\n",
            "- What additional data would improve this analysis?\n",
            "- What limitations prevent deeper insights?\n",
            "- What would you explore next if this were Phase 0 of a larger project?"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Write your reflection here...*"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.1"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
